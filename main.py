# -*- coding: utf-8 -*-
"""개인프로젝트_peter_test11.ipyn

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xICf4MIKSqyG_i6h93SSaeIaceIkO-hX
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install gcsfs

!unzip /content/drive/MyDrive/colab/orange-diseases-dataset.zip -d orange-diseases-dataset

!pip install "pymongo[srv]"==3.12

!pip install pymongo
!pip install --upgrade pymongo

!sudo apt-get update
!sudo apt-get install --reinstall ca-certificates

# ✅ MongoDB 연결
from pymongo import MongoClient
from pymongo.server_api import ServerApi


# 💡 여기에 본인의 MongoDB Atlas URI 입력
MONGODB_URI = "mongodb+srv://gwshim:2OtqnghbiSVMwW4q@cluster0.edb8j.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0"
try:
    client = MongoClient(MONGODB_URI, server_api=ServerApi('1'), tls=True, tlsAllowInvalidCertificates=True)
    db = client["pp-peter-api"]
    collection = db["ai-info"]
    print("✅ MongoDB Atlas 연결 성공!")
except Exception as e:
    print("❌ MongoDB 연결 실패:", e)

import tensorflow as tf
import datetime
from datetime import datetime

class MongoLoggingCallback(tf.keras.callbacks.Callback):
    def on_epoch_begin(self, epoch, logs=None):
        self.epoch_start_time = datetime.utcnow()

    def on_epoch_end(self, epoch, logs=None):
        log = {
            "epoch": epoch + 1,
            "start_time": self.epoch_start_time,
            "end_time": datetime.utcnow(),
            "loss": logs.get("loss"),
            "val_loss": logs.get("val_loss"),
            "accuracy": logs.get("accuracy"),
            "val_accuracy": logs.get("val_accuracy"),
        }
        try:
            collection.insert_one(log)
            print(f"📤 MongoDB에 Epoch {epoch+1} 로그 저장됨")
        except Exception as e:
            print("❌ 로그 저장 실패:", e)

import os
import shutil
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 데이터 경로 설정
data_dir = "/content/orange-diseases-dataset"
train_dir = os.path.join(data_dir, "train")
val_dir = os.path.join(data_dir, "val")

# 클래스 확인
classes = os.listdir(train_dir)
print("클래스 목록:", classes)

"""고급 데이터 증강(Augmentation) 적용
 / 기본 변형: 회전, 이동, 반전, 확대 /
추가 변형: 밝기 조절, 대비 조정, 노이즈 추가
"""

# 이미지 크기 및 배치 설정
IMG_SIZE = (256, 256)
BATCH_SIZE = 32

# 강력한 데이터 증강 적용
train_datagen = ImageDataGenerator(
    rescale=1.0 / 255.0,
    rotation_range=45,  # 회전 범위 증가
    width_shift_range=0.2,  # 가로 이동
    height_shift_range=0.2,  # 세로 이동
    horizontal_flip=True,  # 좌우 반전
    brightness_range=[0.5, 1.5],  # 밝기 조절
    zoom_range=0.3,  # 줌 조정
    shear_range=0.2,  # 기울이기 적용
    channel_shift_range=50.0  # 채널 색상 변형
)

val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)

# 데이터 로딩
train_data = train_datagen.flow_from_directory(
    train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="categorical"
)

val_data = val_datagen.flow_from_directory(
    val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="categorical"
)

"""Pretrained 모델(EfficientNetV2S) 사용
전이 학습 후 일부 레이어를 Fine-Tuning
Dropout 적용하여 과적합 방지
"""

from tensorflow.keras.applications import EfficientNetV2S
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout

# EfficientNetV2 모델 불러오기 (Pretrained weights 사용)
base_model = EfficientNetV2S(weights="imagenet", include_top=False, input_shape=(256, 256, 3))

# 기존 가중치 동결
base_model.trainable = False

# 분류기 추가
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(512, activation="relu")(x)  # 더 큰 히든 레이어 추가
x = Dropout(0.4)(x)  # Dropout 증가
x = Dense(256, activation="relu")(x)
x = Dropout(0.3)(x)
x = Dense(len(classes), activation="softmax")(x)  # 클래스 개수만큼 출력 노드 설정

# 모델 생성
model = Model(inputs=base_model.input, outputs=x)

# 모델 컴파일 (적응형 학습률 사용)
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

# 모델 요약 출력
model.summary()

!pip show pymongo

!python3 -c "import ssl; print(ssl.OPENSSL_VERSION)"

!pip install --upgrade pymongo
!sudo apt-get install --reinstall ca-certificates

from pymongo import MongoClient

try:
    client = MongoClient(
        "mongodb+srv://gwshim:2OtqnghbiSVMwW4q@cluster0.edb8j.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0",
        tls=True,
        tlsAllowInvalidCertificates=True  # ✅ TLS 문제 회피
    )
    db = client["pp-peter-api"]
    collection = db["ai-info"]
    collection.insert_one({"message": "Colab 연결 테스트 완료!"})
    print("✅ 연결 성공! 데이터 저장 완료")
except Exception as e:
    print("❌ 연결 실패:", e)

"""기본학습에 에포크 5 추가"""

mongo_logger = MongoLoggingCallback()

EPOCHS = 30  # 기본 전이 학습

history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=EPOCHS,
    verbose=1,
    callbacks=[mongo_logger]
)

"""상위 30%의 레이어를 학습 가능하도록 설정
2️⃣ 학습률(learning rate) 줄여 세밀한 조정 진행
"""

# EfficientNetV2의 상위 30% 레이어를 학습 가능하게 변경
for layer in base_model.layers[-int(len(base_model.layers) * 0.3):]:
    layer.trainable = True

# 모델 재컴파일 (학습률 감소)
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

# 추가 학습 (Fine-Tuning)
EPOCHS_FINE_TUNE = 10  # 추가 학습 10 Epoch

history_finetune = model.fit(
    train_data,
    validation_data=val_data,
    epochs=EPOCHS_FINE_TUNE,
    verbose=1,
    callbacks=[mongo_logger]
)

import matplotlib.pyplot as plt

# 학습 결과 시각화
plt.figure(figsize=(12, 4))

# Loss 그래프
plt.subplot(1, 2, 1)
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.plot(history_finetune.history["loss"], label="Fine-Tune Train Loss", linestyle="dashed")
plt.plot(history_finetune.history["val_loss"], label="Fine-Tune Validation Loss", linestyle="dashed")
plt.legend()
plt.title("Loss Curve")

# Accuracy 그래프
plt.subplot(1, 2, 2)
plt.plot(history.history["accuracy"], label="Train Accuracy")
plt.plot(history.history["val_accuracy"], label="Validation Accuracy")
plt.plot(history_finetune.history["accuracy"], label="Fine-Tune Train Accuracy", linestyle="dashed")
plt.plot(history_finetune.history["val_accuracy"], label="Fine-Tune Validation Accuracy", linestyle="dashed")
plt.legend()
plt.title("Accuracy Curve")

plt.show()

# 검증 데이터 평가
val_loss, val_acc = model.evaluate(val_data)
print(f"✅ 최종 Validation Accuracy: {val_acc:.4f}")

model.save("/content/drive/MyDrive/colab/orange_disease_model.keras")
print("✅ 모델이 .keras 형식으로 저장되었습니다.")

from tensorflow import keras

model = keras.models.load_model("/content/drive/MyDrive/colab/orange_disease_model.keras")
print("✅ .keras 모델이 성공적으로 로드되었습니다.")

from tensorflow.keras.preprocessing import image
import numpy as np

# 예측 함수 정의
def predict_image(img_path):
    # 이미지 로드 및 전처리
    img = image.load_img(img_path, target_size=IMG_SIZE)
    img_array = image.img_to_array(img)
    img_array = img_array / 255.0  # 정규화
    img_array = np.expand_dims(img_array, axis=0)  # 배치 차원 추가

    # 예측
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions[0])
    class_name = classes[predicted_class]

    # 결과 출력
    print(f"🟠 예측된 클래스: {class_name}")
    plt.imshow(img)
    plt.title(f"Predicted: {class_name}")
    plt.axis("off")
    plt.show()

# 사용 예시 (예측할 이미지 경로 지정)
test_image_path = "/content/rtest_1.jpg"  # 실제 이미지 경로로 바꾸기
predict_image(test_image_path)

from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt
import os

# 예측 함수 정의 (반복용)
def predict_multiple_images(img_paths):
    plt.figure(figsize=(20, 10))

    for i, img_path in enumerate(img_paths):
        if not os.path.exists(img_path):
            print(f"⚠️ 파일 없음: {img_path}")
            continue

        # 이미지 로드 및 전처리
        img = image.load_img(img_path, target_size=IMG_SIZE)
        img_array = image.img_to_array(img)
        img_array = img_array / 255.0
        img_array = np.expand_dims(img_array, axis=0)

        # 예측
        predictions = model.predict(img_array)
        predicted_class = np.argmax(predictions[0])
        class_name = classes[predicted_class]

        # 결과 출력 (서브플롯)
        plt.subplot(3, 4, i + 1)
        plt.imshow(img)
        plt.title(f"{os.path.basename(img_path)}\nPredicted: {class_name}", fontsize=10)
        plt.axis("off")

    plt.tight_layout()
    plt.show()

# 이미지 경로 리스트 생성
test_image_paths = [f"/content/rtest_{i}.jpg" for i in range(1, 12)]

# 예측 실행
predict_multiple_images(test_image_paths)

import pandas as pd

# MongoDB에서 모든 로그 조회 (epoch 순 정렬)
logs = list(collection.find().sort("epoch", 1))

# ObjectId 제거
for log in logs:
    log.pop("_id", None)

# Pandas DataFrame으로 변환
df = pd.DataFrame(logs)

# 날짜 컬럼 포맷 지정 (선택)
df["start_time"] = pd.to_datetime(df["start_time"])
df["end_time"] = pd.to_datetime(df["end_time"])

# 시간 차이 계산
df["duration"] = df["end_time"] - df["start_time"]

# 테이블로 출력
df.style.set_table_attributes("style='display:inline'").set_caption("📊 MongoDB 학습 로그 조회 결과")