# -*- coding: utf-8 -*-
"""ê°œì¸í”„ë¡œì íŠ¸_peter_test11.ipyn

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xICf4MIKSqyG_i6h93SSaeIaceIkO-hX
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install gcsfs

!unzip /content/drive/MyDrive/colab/orange-diseases-dataset.zip -d orange-diseases-dataset

!pip install "pymongo[srv]"==3.12

!pip install pymongo
!pip install --upgrade pymongo

!sudo apt-get update
!sudo apt-get install --reinstall ca-certificates

# âœ… MongoDB ì—°ê²°
from pymongo import MongoClient
from pymongo.server_api import ServerApi


# ğŸ’¡ ì—¬ê¸°ì— ë³¸ì¸ì˜ MongoDB Atlas URI ì…ë ¥
MONGODB_URI = "mongodb+srv://gwshim:2OtqnghbiSVMwW4q@cluster0.edb8j.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0"
try:
    client = MongoClient(MONGODB_URI, server_api=ServerApi('1'), tls=True, tlsAllowInvalidCertificates=True)
    db = client["pp-peter-api"]
    collection = db["ai-info"]
    print("âœ… MongoDB Atlas ì—°ê²° ì„±ê³µ!")
except Exception as e:
    print("âŒ MongoDB ì—°ê²° ì‹¤íŒ¨:", e)

import tensorflow as tf
import datetime
from datetime import datetime

class MongoLoggingCallback(tf.keras.callbacks.Callback):
    def on_epoch_begin(self, epoch, logs=None):
        self.epoch_start_time = datetime.utcnow()

    def on_epoch_end(self, epoch, logs=None):
        log = {
            "epoch": epoch + 1,
            "start_time": self.epoch_start_time,
            "end_time": datetime.utcnow(),
            "loss": logs.get("loss"),
            "val_loss": logs.get("val_loss"),
            "accuracy": logs.get("accuracy"),
            "val_accuracy": logs.get("val_accuracy"),
        }
        try:
            collection.insert_one(log)
            print(f"ğŸ“¤ MongoDBì— Epoch {epoch+1} ë¡œê·¸ ì €ì¥ë¨")
        except Exception as e:
            print("âŒ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨:", e)

import os
import shutil
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
data_dir = "/content/orange-diseases-dataset"
train_dir = os.path.join(data_dir, "train")
val_dir = os.path.join(data_dir, "val")

# í´ë˜ìŠ¤ í™•ì¸
classes = os.listdir(train_dir)
print("í´ë˜ìŠ¤ ëª©ë¡:", classes)

"""ê³ ê¸‰ ë°ì´í„° ì¦ê°•(Augmentation) ì ìš©
 / ê¸°ë³¸ ë³€í˜•: íšŒì „, ì´ë™, ë°˜ì „, í™•ëŒ€ /
ì¶”ê°€ ë³€í˜•: ë°ê¸° ì¡°ì ˆ, ëŒ€ë¹„ ì¡°ì •, ë…¸ì´ì¦ˆ ì¶”ê°€
"""

# ì´ë¯¸ì§€ í¬ê¸° ë° ë°°ì¹˜ ì„¤ì •
IMG_SIZE = (256, 256)
BATCH_SIZE = 32

# ê°•ë ¥í•œ ë°ì´í„° ì¦ê°• ì ìš©
train_datagen = ImageDataGenerator(
    rescale=1.0 / 255.0,
    rotation_range=45,  # íšŒì „ ë²”ìœ„ ì¦ê°€
    width_shift_range=0.2,  # ê°€ë¡œ ì´ë™
    height_shift_range=0.2,  # ì„¸ë¡œ ì´ë™
    horizontal_flip=True,  # ì¢Œìš° ë°˜ì „
    brightness_range=[0.5, 1.5],  # ë°ê¸° ì¡°ì ˆ
    zoom_range=0.3,  # ì¤Œ ì¡°ì •
    shear_range=0.2,  # ê¸°ìš¸ì´ê¸° ì ìš©
    channel_shift_range=50.0  # ì±„ë„ ìƒ‰ìƒ ë³€í˜•
)

val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)

# ë°ì´í„° ë¡œë”©
train_data = train_datagen.flow_from_directory(
    train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="categorical"
)

val_data = val_datagen.flow_from_directory(
    val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="categorical"
)

"""Pretrained ëª¨ë¸(EfficientNetV2S) ì‚¬ìš©
ì „ì´ í•™ìŠµ í›„ ì¼ë¶€ ë ˆì´ì–´ë¥¼ Fine-Tuning
Dropout ì ìš©í•˜ì—¬ ê³¼ì í•© ë°©ì§€
"""

from tensorflow.keras.applications import EfficientNetV2S
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout

# EfficientNetV2 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (Pretrained weights ì‚¬ìš©)
base_model = EfficientNetV2S(weights="imagenet", include_top=False, input_shape=(256, 256, 3))

# ê¸°ì¡´ ê°€ì¤‘ì¹˜ ë™ê²°
base_model.trainable = False

# ë¶„ë¥˜ê¸° ì¶”ê°€
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(512, activation="relu")(x)  # ë” í° íˆë“  ë ˆì´ì–´ ì¶”ê°€
x = Dropout(0.4)(x)  # Dropout ì¦ê°€
x = Dense(256, activation="relu")(x)
x = Dropout(0.3)(x)
x = Dense(len(classes), activation="softmax")(x)  # í´ë˜ìŠ¤ ê°œìˆ˜ë§Œí¼ ì¶œë ¥ ë…¸ë“œ ì„¤ì •

# ëª¨ë¸ ìƒì„±
model = Model(inputs=base_model.input, outputs=x)

# ëª¨ë¸ ì»´íŒŒì¼ (ì ì‘í˜• í•™ìŠµë¥  ì‚¬ìš©)
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

# ëª¨ë¸ ìš”ì•½ ì¶œë ¥
model.summary()

!pip show pymongo

!python3 -c "import ssl; print(ssl.OPENSSL_VERSION)"

!pip install --upgrade pymongo
!sudo apt-get install --reinstall ca-certificates

from pymongo import MongoClient

try:
    client = MongoClient(
        "mongodb+srv://gwshim:2OtqnghbiSVMwW4q@cluster0.edb8j.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0",
        tls=True,
        tlsAllowInvalidCertificates=True  # âœ… TLS ë¬¸ì œ íšŒí”¼
    )
    db = client["pp-peter-api"]
    collection = db["ai-info"]
    collection.insert_one({"message": "Colab ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!"})
    print("âœ… ì—°ê²° ì„±ê³µ! ë°ì´í„° ì €ì¥ ì™„ë£Œ")
except Exception as e:
    print("âŒ ì—°ê²° ì‹¤íŒ¨:", e)

"""ê¸°ë³¸í•™ìŠµì— ì—í¬í¬ 5 ì¶”ê°€"""

mongo_logger = MongoLoggingCallback()

EPOCHS = 30  # ê¸°ë³¸ ì „ì´ í•™ìŠµ

history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=EPOCHS,
    verbose=1,
    callbacks=[mongo_logger]
)

"""ìƒìœ„ 30%ì˜ ë ˆì´ì–´ë¥¼ í•™ìŠµ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
2ï¸âƒ£ í•™ìŠµë¥ (learning rate) ì¤„ì—¬ ì„¸ë°€í•œ ì¡°ì • ì§„í–‰
"""

# EfficientNetV2ì˜ ìƒìœ„ 30% ë ˆì´ì–´ë¥¼ í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ ë³€ê²½
for layer in base_model.layers[-int(len(base_model.layers) * 0.3):]:
    layer.trainable = True

# ëª¨ë¸ ì¬ì»´íŒŒì¼ (í•™ìŠµë¥  ê°ì†Œ)
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

# ì¶”ê°€ í•™ìŠµ (Fine-Tuning)
EPOCHS_FINE_TUNE = 10  # ì¶”ê°€ í•™ìŠµ 10 Epoch

history_finetune = model.fit(
    train_data,
    validation_data=val_data,
    epochs=EPOCHS_FINE_TUNE,
    verbose=1,
    callbacks=[mongo_logger]
)

import matplotlib.pyplot as plt

# í•™ìŠµ ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(12, 4))

# Loss ê·¸ë˜í”„
plt.subplot(1, 2, 1)
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.plot(history_finetune.history["loss"], label="Fine-Tune Train Loss", linestyle="dashed")
plt.plot(history_finetune.history["val_loss"], label="Fine-Tune Validation Loss", linestyle="dashed")
plt.legend()
plt.title("Loss Curve")

# Accuracy ê·¸ë˜í”„
plt.subplot(1, 2, 2)
plt.plot(history.history["accuracy"], label="Train Accuracy")
plt.plot(history.history["val_accuracy"], label="Validation Accuracy")
plt.plot(history_finetune.history["accuracy"], label="Fine-Tune Train Accuracy", linestyle="dashed")
plt.plot(history_finetune.history["val_accuracy"], label="Fine-Tune Validation Accuracy", linestyle="dashed")
plt.legend()
plt.title("Accuracy Curve")

plt.show()

# ê²€ì¦ ë°ì´í„° í‰ê°€
val_loss, val_acc = model.evaluate(val_data)
print(f"âœ… ìµœì¢… Validation Accuracy: {val_acc:.4f}")

model.save("/content/drive/MyDrive/colab/orange_disease_model.keras")
print("âœ… ëª¨ë¸ì´ .keras í˜•ì‹ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

from tensorflow import keras

model = keras.models.load_model("/content/drive/MyDrive/colab/orange_disease_model.keras")
print("âœ… .keras ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

from tensorflow.keras.preprocessing import image
import numpy as np

# ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜
def predict_image(img_path):
    # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
    img = image.load_img(img_path, target_size=IMG_SIZE)
    img_array = image.img_to_array(img)
    img_array = img_array / 255.0  # ì •ê·œí™”
    img_array = np.expand_dims(img_array, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€

    # ì˜ˆì¸¡
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions[0])
    class_name = classes[predicted_class]

    # ê²°ê³¼ ì¶œë ¥
    print(f"ğŸŸ  ì˜ˆì¸¡ëœ í´ë˜ìŠ¤: {class_name}")
    plt.imshow(img)
    plt.title(f"Predicted: {class_name}")
    plt.axis("off")
    plt.show()

# ì‚¬ìš© ì˜ˆì‹œ (ì˜ˆì¸¡í•  ì´ë¯¸ì§€ ê²½ë¡œ ì§€ì •)
test_image_path = "/content/rtest_1.jpg"  # ì‹¤ì œ ì´ë¯¸ì§€ ê²½ë¡œë¡œ ë°”ê¾¸ê¸°
predict_image(test_image_path)

from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt
import os

# ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜ (ë°˜ë³µìš©)
def predict_multiple_images(img_paths):
    plt.figure(figsize=(20, 10))

    for i, img_path in enumerate(img_paths):
        if not os.path.exists(img_path):
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {img_path}")
            continue

        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        img = image.load_img(img_path, target_size=IMG_SIZE)
        img_array = image.img_to_array(img)
        img_array = img_array / 255.0
        img_array = np.expand_dims(img_array, axis=0)

        # ì˜ˆì¸¡
        predictions = model.predict(img_array)
        predicted_class = np.argmax(predictions[0])
        class_name = classes[predicted_class]

        # ê²°ê³¼ ì¶œë ¥ (ì„œë¸Œí”Œë¡¯)
        plt.subplot(3, 4, i + 1)
        plt.imshow(img)
        plt.title(f"{os.path.basename(img_path)}\nPredicted: {class_name}", fontsize=10)
        plt.axis("off")

    plt.tight_layout()
    plt.show()

# ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
test_image_paths = [f"/content/rtest_{i}.jpg" for i in range(1, 12)]

# ì˜ˆì¸¡ ì‹¤í–‰
predict_multiple_images(test_image_paths)

import pandas as pd

# MongoDBì—ì„œ ëª¨ë“  ë¡œê·¸ ì¡°íšŒ (epoch ìˆœ ì •ë ¬)
logs = list(collection.find().sort("epoch", 1))

# ObjectId ì œê±°
for log in logs:
    log.pop("_id", None)

# Pandas DataFrameìœ¼ë¡œ ë³€í™˜
df = pd.DataFrame(logs)

# ë‚ ì§œ ì»¬ëŸ¼ í¬ë§· ì§€ì • (ì„ íƒ)
df["start_time"] = pd.to_datetime(df["start_time"])
df["end_time"] = pd.to_datetime(df["end_time"])

# ì‹œê°„ ì°¨ì´ ê³„ì‚°
df["duration"] = df["end_time"] - df["start_time"]

# í…Œì´ë¸”ë¡œ ì¶œë ¥
df.style.set_table_attributes("style='display:inline'").set_caption("ğŸ“Š MongoDB í•™ìŠµ ë¡œê·¸ ì¡°íšŒ ê²°ê³¼")